{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1166777,"sourceType":"datasetVersion","datasetId":661308},{"sourceId":9637035,"sourceType":"datasetVersion","datasetId":5884119}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom torchvision import transforms, datasets, models\nfrom torch.optim.lr_scheduler import StepLR\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\n\n# DataLoader for loading and augmenting images\nfrom torchvision.transforms import Compose, Resize, ToTensor, Normalize\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\n# Early Stopping implementation\nimport time","metadata":{"_uuid":"47459708-f173-4fed-adf8-b478c96bcfb6","_cell_guid":"2e085c93-df3c-4b65-b04e-b367ff1b799d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T10:35:14.056519Z","iopub.execute_input":"2024-10-20T10:35:14.056885Z","iopub.status.idle":"2024-10-20T10:35:21.370809Z","shell.execute_reply.started":"2024-10-20T10:35:14.056830Z","shell.execute_reply":"2024-10-20T10:35:21.369849Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')","metadata":{"_uuid":"b1c3c6ed-48bb-4d45-b27c-78f4d9803a4b","_cell_guid":"715f816a-c74b-4d3c-a084-d47b979c6ac8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T10:35:21.372757Z","iopub.execute_input":"2024-10-20T10:35:21.373265Z","iopub.status.idle":"2024-10-20T10:35:21.409595Z","shell.execute_reply.started":"2024-10-20T10:35:21.373203Z","shell.execute_reply":"2024-10-20T10:35:21.408495Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Defining the trransfromation steps data aug ,resizing, normalization\ntrain_transforms = transforms.Compose([\n    transforms.Resize((128,128)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet mean/std\n])\ntest_transforms = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"_uuid":"87d221b9-e70a-4359-8bbe-acf56b2a5258","_cell_guid":"69fd0ad5-954e-4714-b236-62debf0f7e3f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T10:35:21.410819Z","iopub.execute_input":"2024-10-20T10:35:21.411126Z","iopub.status.idle":"2024-10-20T10:35:21.420695Z","shell.execute_reply.started":"2024-10-20T10:35:21.411094Z","shell.execute_reply":"2024-10-20T10:35:21.419746Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Loading the data from the train and test directories\ntrain_dataset = datasets.ImageFolder(root='/kaggle/input/dataset/data/train',transform=train_transforms)\nprint(f\"Total training images: {len(train_dataset)}\")\nval_dataset = datasets.ImageFolder(root='/kaggle/input/dataset/data/val',transform=train_transforms)\nprint(f\"Total val images: {len(val_dataset)}\")\ntest_dataset = datasets.ImageFolder(root='/kaggle/input/dataset/data/test', transform=test_transforms)\nprint(f\"Total test images: {len(test_dataset)}\")","metadata":{"_uuid":"22e14037-b470-4a36-bc0a-ab817f73d581","_cell_guid":"280722ba-3fa6-4a4b-8910-c5d8f4fcb11a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T10:35:21.422032Z","iopub.execute_input":"2024-10-20T10:35:21.422476Z","iopub.status.idle":"2024-10-20T10:35:26.376688Z","shell.execute_reply.started":"2024-10-20T10:35:21.422426Z","shell.execute_reply":"2024-10-20T10:35:26.375762Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total training images: 4192\nTotal val images: 1040\nTotal test images: 624\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32,shuffle=False)\nprint(f\"Train_loader:{len(train_loader)}, val_loader:{len(val_loader)}, test_loader:{len(test_loader)}\")","metadata":{"_uuid":"4b9854d8-6e22-41f0-889a-f055fb8134be","_cell_guid":"64175f34-68ab-4b76-acbf-755f48cd5464","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T10:35:26.379362Z","iopub.execute_input":"2024-10-20T10:35:26.379680Z","iopub.status.idle":"2024-10-20T10:35:26.385655Z","shell.execute_reply.started":"2024-10-20T10:35:26.379647Z","shell.execute_reply":"2024-10-20T10:35:26.384695Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Train_loader:131, val_loader:33, test_loader:20\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_loader.dataset.class_to_idx)","metadata":{"_uuid":"a01ce3b6-56f2-48e1-b635-550ff7419c84","_cell_guid":"e570e90c-7e22-43f3-a93e-4764e3cd71ce","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T10:35:26.386807Z","iopub.execute_input":"2024-10-20T10:35:26.387088Z","iopub.status.idle":"2024-10-20T10:35:26.397513Z","shell.execute_reply.started":"2024-10-20T10:35:26.387058Z","shell.execute_reply":"2024-10-20T10:35:26.396577Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'normal': 0, 'opacity': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"\nlistx = []\nfor batch in train_loader:\n    images, labels = batch  # 'labels' is a batch of labels, not a single label\n    for label in labels:  # Iterate over individual labels in the batch\n        if label.item() == 0:  # Convert tensor to scalar value using .item()\n            listx.append(\"Pneumonia\")\n        else:\n            listx.append(\"Normal\")\n\n# Ensure that listx is properly structured and passed as input\nif len(listx) > 0:\n    sns.countplot(x=listx)  # Specify x to avoid errors\n    plt.xlabel(\"Class\")\n    plt.ylabel(\"Count\")\n    plt.title(\"Class Distribution\")\n    plt.show()\n    plt.savefig('training_validation_loss_accuracy.png')\nelse:\n    print(\"List of labels is empty.\")","metadata":{"_uuid":"10cc9cb9-65d2-46d2-bcfa-c33ce2151cad","_cell_guid":"44a9f191-d043-495a-96ec-8ba808afd780","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-20T10:35:26.398488Z","iopub.execute_input":"2024-10-20T10:35:26.398769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass PneumoniaCNN(nn.Module):\n    def __init__(self):\n        super(PneumoniaCNN, self).__init__()\n\n        # First convolutional block\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)  # Batch Normalization\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)  # Batch Normalization\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n\n        # Second convolutional block\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)  # Batch Normalization\n        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.bn4 = nn.BatchNorm2d(256)  # Batch Normalization\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n\n        self.dropout = nn.Dropout(0.5)  # Dropout layer for regularization\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(256 * 32 * 32, 512)  # Adjust according to the input size\n        self.fc2 = nn.Linear(512, 2)  # Binary classification (2 outputs)\n\n    def forward(self, x):\n        # First convolutional block\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool1(x)\n\n        # Second convolutional block\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.pool2(x)\n\n        # Flatten the feature map\n        x = x.view(x.size(0), -1)  # Flatten the tensor\n        x = self.dropout(x)  # Apply dropout\n\n        # Fully connected layers\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)  # Logits for binary classification\n\n        return x\n\n# Step 2: Define your model (assuming 'model' is your defined CNN)\nmodel = PneumoniaCNN() \nmodel = model.to(device)  # Move the model to GPU\n\n# Initialize the model, loss function, and optimizer\n#model = PneumoniaCNN()\ncriterion = nn.CrossEntropyLoss()  # For multi-class classification\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n# Define your model, criterion, and optimizer\nmodel = PneumoniaCNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(Mymodel.parameters(), lr=0.001)\n\n# Initialize the StepLR scheduler\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Adjust step_size and gamma as needed","metadata":{"_uuid":"30762600-dc78-44f6-a8da-2b754b498fed","_cell_guid":"2a31d5dc-ad7a-4465-9731-13810af3eb3f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Assuming model, train_loader, val_loader, criterion, and optimizer are already defined\ndef evaluate_train(train_loader,val_loader,model,num_epochs):\n    # Define the number of epochs\n    #num_epochs = 10\n\n    correct=0\n    total =0\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n    # Start training\n\n    for epoch in range(num_epochs):\n        model.train()  # Set the model to training mode\n        running_loss = 0.0\n\n        for images, labels in train_loader:  # Iterate over the training data\n            images, labels = images.to(device), labels.to(device)\n            # Zero the gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(images)  # Get predictions from the model\n\n            # Calculate the loss\n            loss = criterion(outputs, labels)  # Compare predictions to true labels\n\n            # Backward pass\n            loss.backward()  # Compute gradients\n\n            # Update the weights\n            optimizer.step()  # Adjust the model parameters\n\n            # Accumulate the loss for logging\n            running_loss += loss.item()\n\n            # Calculate accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        # Calculate average loss for the epoch\n        avg_loss = running_loss / len(train_loader)\n\n        train_accuracy = 100 * correct / total\n        train_losses.append(avg_loss)\n        train_accuracies.append(train_accuracy)\n        print(f\"Epoch [{epoch + 1}/{num_epochs}], \\n Train_Loss: {avg_loss:.4f}, Train_accuracy:{train_accuracy} \")\n\n        # (Optional) Validate the model\n        model.eval()  # Set the model to evaluation mode\n        with torch.no_grad():  # Disable gradient computation\n            val_loss = 0.0\n            correct = 0\n            total = 0\n            for val_images, val_labels in val_loader:\n                val_images, val_labels = val_images.to(device), val_labels.to(device)\n                val_outputs = model(val_images)\n                val_loss += criterion(val_outputs, val_labels).item()\n                _, predicted = torch.max(val_outputs.data, 1)  # Get predicted classes\n                total += val_labels.size(0)  # Total number of samples\n                correct += (predicted == val_labels).sum().item()  # Count correct predictions\n\n\n            avg_val_loss = val_loss / len(val_loader)\n            val_accuracy = 100 * correct / total\n            val_losses.append(avg_val_loss)\n            val_accuracies.append(val_accuracy)\n            print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n    return train_losses,train_accuracies,val_losses,val_accuracies","metadata":{"_uuid":"fc54b6bf-6ab1-4e7d-9e35-fc88dcef5893","_cell_guid":"44820f73-85ba-4047-9380-c64dff7f0e99","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_train_val(train_losses,train_accuracies,val_losses,val_accuracies):\n    plt.figure(figsize=(12,5))\n\n    plt.subplot(1,2,1)\n    plt.plot(train_losses, label='Training Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.title('Loss over eposchs')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.subplot(1,2,2)\n    plt.plot(train_accuracies, label='Training Accuracy')\n    plt.plot(val_accuracies, label='Validation Accuracy')\n    plt.title('Accuracy over epochs')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n\n    plt.tight_layout()\n\n    plt.savefig('training_validation_loss_accuracy.png')  # Save as a PNG file\n    plt.show()\n\n    plt.close()","metadata":{"_uuid":"6310de3c-1763-43ef-ba4f-fdf96432406f","_cell_guid":"a5758ff6-82c9-4b4d-91b2-b192463fafb6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_matrix_plot(test_loader,model):\n# Assuming you have your model evaluation loop to get predictions\n    predicted = []\n    all_labels = []\n\n    # Model evaluation\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():\n        for images, labels in test_loader:  # Replace with your data loader\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            predicted.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Calculate confusion matrix\n    cm = confusion_matrix(all_labels, predicted)\n    tn, fp, fn, tp = cm.ravel()  # Extract values\n\n\n    # Print TP, FP, TN, FN\n    print(f\"True Positives: {tp}\")\n    print(f\"False Positives: {fp}\")\n    print(f\"True Negatives: {tn}\")\n    print(f\"False Negatives: {fn}\")\n\n    # Normalize the confusion matrix to get percentages\n    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n    # Plot confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=['Normal', 'Pneumonia'], yticklabels=['Normal', 'Pneumonia'])\n\n    # Add TP and FN text to the heatmap\n    plt.text(0.5, 0.3, f'True Negative', ha='center', va='center', color='black', fontsize=12)\n    plt.text(0.5, 1.3, f'False Negative', ha='center', va='center', color='black', fontsize=12)\n    plt.text(1.5, 0.3, f'False Positive', ha='center', va='center', color='black', fontsize=12)\n    plt.text(1.5, 1.3, f'True Positive', ha='center', va='center', color='white', fontsize=12)\n\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.title('Confusion Matrix with TP, FN, FP, TN')\n    plt.savefig('confusion_matrix_with_metrics.png')  # Save confusion matrix as an image\n    plt.show()","metadata":{"_uuid":"998a6224-bf8f-4e04-8f0a-ff94b7aa525f","_cell_guid":"402584fc-54cc-4ef6-a351-721e208cf043","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_roc_auc(test_loader,model):\n    # Collect predictions and true labels\n    all_labels = []\n    all_probs = []\n\n    model.eval()  # Set the model to evaluation mode\n    with torch.no_grad():  # Disable gradient computation\n        for test_images, test_labels in test_loader:\n            test_images, test_labels = test_images.to(device), test_labels.to(device)\n            test_outputs = model(test_images)\n\n            # Get probabilities for the positive class (assuming class 1 is pneumonia)\n            test_probs = torch.softmax(test_outputs, dim=1)[:, 1].cpu().numpy()\n\n            all_labels.extend(test_labels.cpu().numpy())  # Collect labels\n            all_probs.extend(test_probs)  # Collect probabilities\n\n    all_labels = np.array(all_labels)\n    all_probs = np.array(all_probs)\n\n    # Calculate ROC AUC\n    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n    roc_auc = auc(fpr, tpr)\n\n    # Plot ROC curve\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.savefig(\"roc_curve_train_test.png\")  # Save the ROC curve as a PNG file\n    plt.show()  # Display the plot\n    print(f\"AUC:{roc_auc * 100:.2f}%\")","metadata":{"_uuid":"d21e2a34-8b3c-437e-86dc-ca678413f14f","_cell_guid":"75457a40-a530-46dd-9173-f4f72e17cea6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overfitting to a small subset\nsmall_dataset_size = 10  # Choose a small number of samples for overfitting\nsmall_dataset = Subset(train_dataset, list(range(small_dataset_size)))  # Select first N samples\n\n# Create data loader for small dataset\nsmall_train_loader = DataLoader(small_dataset, batch_size=2, shuffle=True)\nevaluate_train(small_train_loader,val_loader,Mymodel,num_epochs=5)","metadata":{"_uuid":"ccd981f9-1dda-4a47-8a5c-1492aa60efea","_cell_guid":"8b25ea5b-3d68-42d9-bb97-4b5a833dae47","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_train(train_loader,val_loader,Mymodel,num_epochs=5)","metadata":{"_uuid":"9ca3a4b3-cb3f-4c3d-9be7-0d6e9974aeb5","_cell_guid":"b15a4949-242d-4ba9-a5f1-fcc0ec5f4b6b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix_plot(test_loader)","metadata":{"_uuid":"3239e3c6-e86f-4449-9642-59a7b3210ada","_cell_guid":"777eb2e3-273c-4998-930f-96d17e95545f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n# Load pre-trained ResNet-50 model\nresnet = models.resnet50(pretrained=True)\nnum_classes = 2  # Assuming \"normal\" and \"opacity\"\nresnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nresnet.to(device)\ncriterion = nn.CrossEntropyLoss()  # For multi-class classification\noptimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)  # Adjust the learning rate as needed\nscheduler = StepLR(optimizer, step_size=3, gamma=0.1)  # Adjust step_size and gamma as needed\n\n# Set the model to evaluation mode (important for inference)\nresnet.eval()\ntrain_losses,train_accuracies,val_losses,val_accuracies=evaluate_train(train_loader,val_loader,model=resnet,num_epochs=10)","metadata":{"_uuid":"905ca6d6-9150-4e73-94a1-bfd0152fcd94","_cell_guid":"be4607b4-0993-4ded-90e6-c985c48877e8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_val(train_losses,train_accuracies,val_losses,val_accuracies)","metadata":{"_uuid":"711f10c9-578a-430b-ba0a-027924d38d78","_cell_guid":"b67ad9e1-8470-4c77-a483-f7ea6c9fa01e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'model' is your trained model\n\n# Save the model in HDF5 format\nMymodel.save('pneumonia_model.h5')\nprint(\"Model saved to pneumonia_model.h5\")","metadata":{"_uuid":"58798041-0322-4712-8828-e746007249db","_cell_guid":"8ab0abbf-1346-4dba-b7c1-cea96876463c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the entire model\ntorch.save(model, 'pneumonia_cnn_model.pth')\nprint(\"Model saved as pneumonia_cnn_model.pth\")","metadata":{"_uuid":"5384d36c-50d2-4f1c-ac3d-663b0bc0a855","_cell_guid":"018ccc0a-bc94-4e42-8625-522b9fed80b0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"97f0d57d-f568-4b0b-8035-4a729326bc50","_cell_guid":"d7a0c874-8260-40f8-bfec-85c1e83d379f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}